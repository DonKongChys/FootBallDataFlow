# Introduction 
This Python project utilizes Apache Airflow to scrape data from Wikipedia, clean it, and then upload it to Azure Data Lake for further processing.

# Architecture
![image](https://github.com/user-attachments/assets/dd08651a-939c-44c4-ad0f-7f45da9e24da)

# Tools and technology
- Python
- Docker
- PostgreSQL
- Apache Airflow
# Work flow
- Extract and clean data from Wikipedia with python, Apache Airflow and process them into lake (Azure data gen 2)
- Using the Azure Synapse to query data
- Building dashboard with Tableau
