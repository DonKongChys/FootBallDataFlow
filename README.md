# Introduction 
This Python project utilizes Apache Airflow to scrape data from Wikipedia, clean it, and then upload it to Azure Data Lake for further processing.

# Architecture
![image](https://github.com/user-attachments/assets/1d6d7071-49ca-4731-a9d6-d59b7c58846b)
# Tools and technology
- Python
- Docker
- PostgreSQL
- Apache Airflow
# Work flow
- Extract data from Wikipedia with Apache Airflow
- Data Cleaning Strategy
- Creating and Setting up Azure Architecture
- Perform Data Integration with Azure Data Flow
