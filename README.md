# Introduction 
This Python project utilizes Apache Airflow to scrape data from Wikipedia, clean it, and then upload it to Azure Data Lake for further processing.

# Architecture
![image](https://github.com/user-attachments/assets/dd08651a-939c-44c4-ad0f-7f45da9e24da)

# Tools and technology
- Python
- Docker
- PostgreSQL
- Apache Airflow
# Work flow
- Extract data from Wikipedia with Apache Airflow
- Data Cleaning Strategy
- Creating and Setting up Azure Architecture
- Perform Data Integration with Azure Data Flow
